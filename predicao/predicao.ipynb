{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\moura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "\n",
    "# Ensure nltk punkt tokenizer is downloaded\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Aplicação de Predição**\n",
      "Selecione o modelo de IA:\n",
      "\n",
      "1. Randon Forest em Ensaios\n",
      "2. Randon Forest em textos curtos\n",
      "\n",
      "Resultado da Predição:\n",
      "\n",
      "  cEXT cNEU cAGR cCON cOPN\n",
      "0  Sim  Sim  Sim  Sim  Sim\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "# Load the SentenceTransformer model\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "def load_model(model_path):\n",
    "    with open(model_path, \"rb\") as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "def make_prediction(user_text, selected_model):\n",
    "    # Process the text\n",
    "    sentences = nltk.sent_tokenize(user_text)\n",
    "    embeddings = [model.encode(sentence) for sentence in sentences]\n",
    "    essay_embedding = sum(embeddings) / len(embeddings)\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = selected_model.predict([essay_embedding])[0]\n",
    "    \n",
    "    # Convert 0s to \"Não\" and 1s to \"Sim\"\n",
    "    return ['Sim' if pred == 1 else 'Não' for pred in prediction]\n",
    "\n",
    "def main():\n",
    "    print(\"**Aplicação de Predição**\")\n",
    "    \n",
    "    # Model selection dropdown\n",
    "    print(\"Selecione o modelo de IA:\\n\")\n",
    "    print(\"1. Randon Forest em Ensaios\")\n",
    "    print(\"2. Randon Forest em textos curtos\")\n",
    "    \n",
    "    model_option = input()\n",
    "\n",
    "    if model_option == \"1\":\n",
    "        loaded_model = load_model(\"C:/Users/moura/Projetos/Colab-Essays/forest-essays/random_forest_model.pkl\")  # Model 1 path\n",
    "    elif model_option == \"2\":\n",
    "        loaded_model = load_model(\"C:/Users/moura/Projetos/Colab-Essays/forest-mypersonality/mypersonality_forest.pkl\")  # Model 2 path\n",
    "    else:\n",
    "        print('Você não escolheu nenhum modelo')\n",
    "        #loaded_model = load_model(\"C:/Users/moura/Projetos/Colab-Essays/LSTM-essays/model_LSTM.pkl\")  # Model 3 path\n",
    "\n",
    "    # User input for text\n",
    "    user_text = input(\"Por favor, insira o texto:\\n\")\n",
    "    \n",
    "    prediction = make_prediction(user_text, loaded_model)\n",
    "    \n",
    "    columns = [\"cEXT\", \"cNEU\", \"cAGR\", \"cCON\", \"cOPN\"]\n",
    "    df = pd.DataFrame([prediction], columns=columns)\n",
    "    \n",
    "    \n",
    "    print(\"\\nResultado da Predição:\\n\")\n",
    "    print(df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colab_essays",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
