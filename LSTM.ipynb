{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\moura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "# Ensure nltk punkt tokenizer is downloaded (needed to split paragraphs into sentences)\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 1. Carregar o dataset e pré-processar\n",
    "\n",
    "essays_df = pd.read_csv(\"C:/Users/moura/Projetos/Colab-Essays/essays.csv\", encoding=\"latin-1\")\n",
    "\n",
    "\n",
    "# Dividir os ensaios em sentenças\n",
    "essays_df['sentences'] = essays_df['TEXT'].apply(nltk.sent_tokenize)\n",
    "\n",
    "# Converter 'y' e 'n' para '1' e '0'\n",
    "label_columns = ['cEXT', 'cNEU', 'cAGR', 'cCON', 'cOPN']\n",
    "binarizer = LabelBinarizer()\n",
    "for col in label_columns:\n",
    "    essays_df[col] = binarizer.fit_transform(essays_df[col])\n",
    "\n",
    "# 2. Obter embeddings das sentenças usando SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "essays_df['embeddings'] = essays_df['sentences'].apply(lambda sentences: [model.encode(sentence) for sentence in sentences])\n",
    "\n",
    "# 3. Agregar embeddings para representar o ensaio completo\n",
    "\n",
    "essays_df['essay_embedding'] = essays_df['embeddings'].apply(lambda embeddings: np.mean(embeddings, axis=0))\n",
    "\n",
    "# 4. Dividir os dados em conjuntos de treinamento e teste\n",
    "\n",
    "X = np.array(essays_df['essay_embedding'].tolist())\n",
    "y = essays_df[label_columns].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 5. Construir e treinar um modelo LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(X_train.shape[1], 1), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(64, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Reshape data for LSTM\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "# 6. Avaliar o modelo no conjunto de teste\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Vamos analisar as informações solicitadas com base no novo código fornecido:\n",
    "\n",
    "Quais são os pré-processamentos presentes?\n",
    "\n",
    "Tokenização de sentenças: O texto é dividido em sentenças usando nltk.sent_tokenize.\n",
    "Conversão de etiquetas: As etiquetas 'y' e 'n' são convertidas para '1' e '0', respectivamente.\n",
    "Obtenção de embeddings: Cada sentença do texto é convertida em um embedding usando o modelo SentenceTransformer.\n",
    "Agregação de embeddings: Os embeddings de todas as sentenças de um ensaio são agregados (média) para formar um único embedding que representa o ensaio inteiro.\n",
    "Qual o modelo de IA usado?\n",
    "\n",
    "É usado um modelo de Rede Neural com camadas LSTM (Long Short-Term Memory).\n",
    "O quão robusto precisa ser meu computador para executar esse código?\n",
    "\n",
    "LSTM é menos intensivo do que modelos como BERT, mas ainda requer uma quantidade razoável de RAM e, idealmente, uma GPU para treinamento mais rápido. Uma máquina com pelo menos 8GB de RAM e uma GPU moderna seria ideal, embora seja possível executar o código em máquinas menos potentes (o treinamento seria apenas mais lento).\n",
    "Quais são os otimizadores e loss para otimização?\n",
    "\n",
    "Otimizador: Adam com uma taxa de aprendizado de 0.001.\n",
    "Loss: A função de perda é binary_crossentropy, que é comumente usada para tarefas de classificação binária.\n",
    "Qual é o evaluator?\n",
    "\n",
    "O modelo é avaliado usando a métrica de acurácia (accuracy), que compara as previsões do modelo com as verdadeiras etiquetas.\n",
    "Existem possíveis otimizações?\n",
    "\n",
    "Sim, algumas possíveis otimizações incluem:\n",
    "Ajustar os hiperparâmetros do modelo LSTM, como o número de neurônios, a taxa de dropout ou a taxa de aprendizado.\n",
    "Experimentar outras arquiteturas de rede neural, como GRU ou combinações de LSTM e CNN.\n",
    "Usar técnicas de aumento de dados para expandir o conjunto de treinamento.\n",
    "Ajustar e afinar os embeddings, possivelmente treinando um modelo de embedding do zero.\n",
    "Quais são as métricas mais plausíveis de se escolher para analisar esse resultado?\n",
    "\n",
    "Acurácia: Fornece uma visão geral do desempenho do modelo.\n",
    "Precisão, Recall e F1-Score: Essas métricas são particularmente importantes para avaliar o desempenho em categorias desequilibradas.\n",
    "ROC e AUC: Se o modelo for adaptado para fornecer probabilidades, a curva ROC e a métrica AUC podem ser úteis para avaliar o desempenho em diferentes limiares.\n",
    "Matriz de Confusão: Fornece uma visão detalhada de onde o modelo está cometendo erros.\n",
    "Espero que isso ajude a esclarecer as especificações e características do código fornecido! Se você tiver mais perguntas ou precisar de mais esclarecimentos, estou à disposição."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colab_essays",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
